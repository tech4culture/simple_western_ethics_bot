# -*- coding: utf-8 -*-
"""MyWesternEthicsbot_rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1560FgHmnK2dNO6fHT5ROs0H0Nq0wld3F
"""

"""
Clean Western Ethics RAG System - Bulletproof Version
Cleaned up version focusing only on the bulletproof system with progressive expansion
"""

# =============================================================================
# STEP 1: INSTALL REQUIRED PACKAGES
# =============================================================================



# =============================================================================
# STEP 2: IMPORT LIBRARIES
# =============================================================================

import chromadb
from sentence_transformers import SentenceTransformer
import anthropic
import PyPDF2
import ebooklib
from ebooklib import epub
import os
from typing import List, Dict
import re
from bs4 import BeautifulSoup
import glob
from pathlib import Path
import json
from datetime import datetime
<<<<<<< HEAD
# import textwrap
=======
#import textwrap
>>>>>>> 269a619e1c3be0cd4dbfec94889d818391b8efbf
import httpx
print(f"httpx version: {httpx.__version__}")
from langdetect import detect
from llama_index.core import Document
print("‚úÖ All libraries imported successfully!")

#THE WORKS CHOSEN
# =============================================================================

def get_western_ethics_config():
    """Configuration des textes Western Ethics avec skip pages + info langues"""
    return {
        "AnIntrotoPrinciplesofMoral_Bentham.pdf": {
            "skip_start": 4, "skip_end": 1,
            "author": "Bentham", "language": "anglais", "type": "pdf"
        },
        "Critiquedelaraisonpure.pdf": {
            "skip_start": 23, "skip_end": 1,
            "author": "Kant", "language": "fran√ßais", "type": "pdf"
        },
        "CritiquedelaraisonpratiqueKant.pdf": {
            "skip_start": 1, "skip_end": 15,
            "author": "Kant", "language": "anglais", "type": "epub"
        },
        "ethique_de_Spinoza.pdf": {
            "skip_start": 9, "skip_end": 0,
            "author": "Spinoza", "language": "fran√ßais", "type": "pdf"
        },
        "StAugustineTheConfessions.pdf": {
            "skip_start": 36, "skip_end": 74,
            "author": "Augustine", "language": "anglais", "type": "pdf"
        },
        "atheoryofjustice_rawls.pdf": {
            "skip_start": 10, "skip_end": 46,
            "author": "Rawls", "language": "anglais", "type": "pdf"
        },
        "MillOnLiberty.pdf": {
            "skip_start": 4, "skip_end": 0,
            "author": "Mill", "language": "anglais", "type": "pdf"
        },
        "Gorgias.pdf": {
            "skip_start": 15, "skip_end": 61,
            "author": "Platon", "language": "fran√ßais", "type": "pdf"
        },
        "HobbesLeviathan_extract.pdf": {
            "skip_start": 7, "skip_end": 1,
            "author": "Hobbes", "language": "anglais", "type": "pdf"
        }
    }

# =============================================================================
# FILE LOADING FUNCTIONS
# =============================================================================

def load_file_versatile(filepath, skip_start=0, skip_end=0):
    
    from PyPDF2 import PdfReader
    from llama_index.core import Document
    import zipfile
    from bs4 import BeautifulSoup

    filepath = Path(filepath)
    print(f"üìñ Chargement: {filepath.name} (type: {filepath.suffix})")

    if not filepath.exists():
        raise FileNotFoundError(f"Fichier non trouv√©: {filepath}")

    if filepath.suffix.lower() == '.pdf':
        return load_pdf_with_skip_pages(filepath, skip_start, skip_end)
    
    else:
        raise ValueError(f"Format non support√©: {filepath.suffix}")

def load_pdf_with_skip_pages(filepath, skip_start=0, skip_end=0):
    """Chargement PDF avec skip pages"""
    from PyPDF2 import PdfReader
    from llama_index.core import Document

    reader = PdfReader(filepath)
    total_pages = len(reader.pages)

    start_page = skip_start
    end_page = total_pages - skip_end

    print(f"üìä PDF: {total_pages} pages total")
    print(f"üìÑ Pages gard√©es: {start_page} √† {end_page-1} (soit {end_page-start_page} pages)")

    if start_page >= end_page:
        print(f"‚ùå ERREUR: Skip trop important (start={start_page}, end={end_page})")
        return []

    clean_text = ""
    for i in range(start_page, end_page):
        try:
            page_text = reader.pages[i].extract_text()
            clean_text += page_text + "\n"
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur page {i}: {e}")
            continue

    print(f"‚úÖ Texte extrait: {len(clean_text)} caract√®res")
    return [Document(text=clean_text)]





def chunk_text(text, chunk_size=900, overlap=150):
    """Chunking function with overlap"""
    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size

        if end < len(text):
            last_period = text.rfind('.', start, end)
            if last_period > start + chunk_size * 0.5:
                end = last_period + 1

        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)

        start = end - overlap

    return chunks

"""# New section"""

# 1. Elements pour gerer la traduction

class SimpleTranslator:
    """Traducteur via Claude - AJOUTEZ AVANT VOTRE BOT"""

    def __init__(self, anthropic_client):
        self.anthropic_client = anthropic_client
        self.cache = {}

    def translate_text(self, text: str, target_lang: str) -> str:
        cache_key = f"{hash(text)}_{target_lang}"
        if cache_key in self.cache:
            return self.cache[cache_key]

        if target_lang == 'fr':
            return text

        try:
            lang_names = {'en': 'English', 'es': 'Spanish', 'de': 'German'}
            prompt = f'Translate to {lang_names.get(target_lang, "English")}: "{text}"'

            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=200,
                messages=[{"role": "user", "content": prompt}]
            )

            result = response.content[0].text.strip()
            self.cache[cache_key] = result
            return result
        except:
            return text

class SimpleLangDetector:
    """D√©tecteur simple - AJOUTEZ AVANT VOTRE BOT"""

    def detect_language(self, text: str) -> str:
        text_lower = text.lower()

        # Compteurs simples
        fr_score = sum(1 for word in ['qu\'est-ce', 'comment', '√©thique', 'justice'] if word in text_lower)
        en_score = sum(1 for word in ['what', 'how', 'ethics', 'justice'] if word in text_lower)
        es_score = sum(1 for word in ['qu√©', 'c√≥mo', '√©tica', 'justicia'] if word in text_lower)
        de_score = sum(1 for word in ['was', 'wie', 'ethik', 'gerechtigkeit'] if word in text_lower)

        scores = {'fr': fr_score, 'en': en_score, 'es': es_score, 'de': de_score}
        detected = max(scores, key=scores.get)
        return detected if scores[detected] > 0 else 'en'

# =============================================================================
# BULLETPROOF RAG SYSTEM
# =============================================================================

class BulletproofRAGSystem:
    """
    Syst√®me RAG qui √©vite les √©crasements et permet l'ajout incr√©mental
    """

    def __init__(self, db_path="./chroma_db_bulletproof", anthropic_api_key=None):
        print("üõ°Ô∏è  Initialisation syst√®me RAG Bulletproof")

        self.db_path = Path(db_path)
        self.db_path.mkdir(exist_ok=True)

        # Client persistant
        self.client = chromadb.PersistentClient(path=str(self.db_path))

        # Mod√®le embedding multilingue
        print("üåç Chargement mod√®le embedding multilingue...")
        self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

        # Anthropic client
        if anthropic_api_key:
            import anthropic
            self.anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key)
        else:
            self.anthropic_client = None

        # Registre des sources (√©vite les √©crasements)
        self.sources_registry_file = self.db_path / "sources_registry.json"
        self.sources_registry = self._load_sources_registry()

        print("‚úÖ Syst√®me bulletproof initialis√©")

    def _load_sources_registry(self):
        """Charge le registre des sources d√©j√† trait√©es"""
        if self.sources_registry_file.exists():
            with open(self.sources_registry_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def _save_sources_registry(self):
        """Sauvegarde le registre des sources"""
        with open(self.sources_registry_file, 'w', encoding='utf-8') as f:
            json.dump(self.sources_registry, f, indent=2, ensure_ascii=False)

    def get_collection_safely(self, collection_name="western_ethics_safe"):
        """R√©cup√®re ou cr√©e une collection de mani√®re s√ªre"""
        try:
            collection = self.client.get_collection(collection_name)
            print(f"üìÇ Collection '{collection_name}' charg√©e: {collection.count()} documents")
        except:
            print(f"üìù Cr√©ation nouvelle collection '{collection_name}'")
            collection = self.client.create_collection(
                name=collection_name,
                metadata={
                    "description": "Western Ethics - Anti-√âcrasement",
                    "created_at": str(datetime.now()),
                    "bulletproof": True
                }
            )
        return collection

    def analyze_available_sources(self, folder_path="./Livres_philo"):
        """Analyse les sources disponibles vs celles d√©j√† trait√©es"""
        print("üîç ANALYSE DES SOURCES")
        print("=" * 50)

        config = get_western_ethics_config()
        folder_path = Path(folder_path)

        available_sources = []
        missing_sources = []
        already_processed = []

        for filename, file_config in config.items():
            filepath = folder_path / filename

            if filepath.exists():
                file_info = {
                    "filename": filename,
                    "filepath": str(filepath),
                    "config": file_config,
                    "size": filepath.stat().st_size,
                    "exists": True
                }

                # V√©rifier si d√©j√† trait√©
                if filename in self.sources_registry:
                    already_processed.append(file_info)
                    print(f"‚úÖ {filename} - D√©j√† trait√© ({file_info['size']} bytes)")
                else:
                    available_sources.append(file_info)
                    print(f"üÜï {filename} - Nouveau ({file_info['size']} bytes)")
            else:
                missing_sources.append(filename)
                print(f"‚ùå {filename} - Manquant")

        print(f"\nüìä R√âSUM√â:")
        print(f"   üÜï Nouveaux: {len(available_sources)}")
        print(f"   ‚úÖ D√©j√† trait√©s: {len(already_processed)}")
        print(f"   ‚ùå Manquants: {len(missing_sources)}")

        return {
            "new_sources": available_sources,
            "processed_sources": already_processed,
            "missing_sources": missing_sources
        }

    def process_single_source_safely(self, source_info):
        """Traite UNE source de mani√®re isol√©e et s√ªre"""
        filename = source_info["filename"]
        print(f"\nüìñ TRAITEMENT ISOL√â: {filename}")
        print("-" * 40)

        # Chargement isol√©
        try:
            documents = load_file_versatile(
                source_info["filepath"],
                skip_start=source_info["config"]["skip_start"],
                skip_end=source_info["config"]["skip_end"]
            )

            if not documents:
                print(f"‚ùå Aucun contenu extrait de {filename}")
                return None

            print(f"‚úÖ Texte extrait: {len(documents[0].text)} caract√®res")

            # Enrichir avec m√©tadonn√©es S√âCURIS√âES
            enhanced_doc = self._add_bulletproof_metadata(documents[0], source_info)

            # Chunking ISOL√â (pas de m√©lange possible)
            chunks = self._chunk_single_document(enhanced_doc, source_info)

            print(f"‚úÇÔ∏è  {len(chunks)} chunks cr√©√©s pour {filename}")

            return {
                "source_info": source_info,
                "chunks": chunks,
                "chunk_count": len(chunks),
                "total_chars": len(enhanced_doc.text)
            }

        except Exception as e:
            print(f"‚ùå Erreur traitement {filename}: {e}")
            return None

    def _add_bulletproof_metadata(self, document, source_info):
        """Ajoute des m√©tadonn√©es bulletproof"""
        from llama_index.core import Document

        # M√©tadonn√©es enrichies et s√©curis√©es
        source_id = f"SRC_{source_info['filename']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        enhanced_text = f"""[BULLETPROOF_METADATA]
[SOURCE_ID: {source_id}]
[SOURCE_FILE: {source_info['filename']}]
[AUTHOR: {source_info['config']['author']}]
[LANGUAGE: {source_info['config']['language']}]
[PROCESSED_AT: {datetime.now().isoformat()}]
[FILE_SIZE: {source_info['size']} bytes]
[SKIP_CONFIG: start={source_info['config']['skip_start']}, end={source_info['config']['skip_end']}]
[/BULLETPROOF_METADATA]

{document.text}"""

        return Document(text=enhanced_text)

    def _chunk_single_document(self, document, source_info):
        """Chunking d'un seul document (isolation totale)"""
        chunks = chunk_text(document.text, chunk_size=900, overlap=150)

        # V√©rifier que chaque chunk garde les m√©tadonn√©es
        verified_chunks = []
        for i, chunk in enumerate(chunks):
            if "[BULLETPROOF_METADATA]" in chunk:
                verified_chunks.append(chunk)
            else:
                # Reconstituer les m√©tadonn√©es si perdues
                repaired_chunk = self._repair_chunk_metadata(chunk, source_info, i)
                verified_chunks.append(repaired_chunk)

        return verified_chunks

    def _repair_chunk_metadata(self, chunk, source_info, chunk_index):
        """R√©pare un chunk qui a perdu ses m√©tadonn√©es"""
        source_id = f"SRC_{source_info['filename']}_REPAIRED_{chunk_index}"

        repaired = f"""[BULLETPROOF_METADATA]
[SOURCE_ID: {source_id}]
[SOURCE_FILE: {source_info['filename']}]
[AUTHOR: {source_info['config']['author']}]
[CHUNK_INDEX: {chunk_index}]
[REPAIRED: True]
[/BULLETPROOF_METADATA]

{chunk}"""

        return repaired

    def add_sources_incrementally(self, collection_name="western_ethics_safe"):
        """Ajoute les sources de mani√®re incr√©mentale et s√ªre"""
        print("üîÑ AJOUT INCR√âMENTAL S√âCURIS√â")
        print("=" * 60)

        # Analyser les sources
        analysis = self.analyze_available_sources()

        if not analysis["new_sources"]:
            print("‚úÖ Aucune nouvelle source √† traiter")
            return self.get_collection_safely(collection_name)

        collection = self.get_collection_safely(collection_name)
        initial_count = collection.count()

        print(f"\nüì¶ Traitement de {len(analysis['new_sources'])} nouvelles sources")

        total_chunks_added = 0

        for source_info in analysis["new_sources"]:
            print(f"\n" + "="*50)

            # Traitement isol√© de chaque source
            result = self.process_single_source_safely(source_info)

            if not result:
                continue

            # Ajout s√©curis√© √† la collection
            chunks_added = self._add_chunks_to_collection(
                collection, result["chunks"], source_info, initial_count + total_chunks_added
            )

            if chunks_added > 0:
                # Marquer comme trait√© dans le registre
                self.sources_registry[source_info["filename"]] = {
                    "processed_at": datetime.now().isoformat(),
                    "chunks_count": chunks_added,
                    "total_chars": result["total_chars"],
                    "author": source_info["config"]["author"]
                }

                total_chunks_added += chunks_added
                print(f"‚úÖ {source_info['filename']}: {chunks_added} chunks ajout√©s")
            else:
                print(f"‚ùå {source_info['filename']}: √âchec ajout")

        # Sauvegarder le registre
        self._save_sources_registry()

        final_count = collection.count()
        print(f"\nüéâ AJOUT TERMIN√â")
        print(f"üìä Collection: {initial_count} ‚Üí {final_count} documents (+{total_chunks_added})")

        return collection

    def _add_chunks_to_collection(self, collection, chunks, source_info, start_index):
        """Ajoute les chunks √† la collection de mani√®re s√ªre"""
        print(f"üíæ Ajout de {len(chunks)} chunks pour {source_info['filename']}")

        batch_size = 30
        chunks_added = 0

        try:
            for i in range(0, len(chunks), batch_size):
                batch = chunks[i:i + batch_size]

                # Embeddings
                embeddings = self.embedding_model.encode(batch).tolist()

                # IDs uniques
                ids = [f"chunk_{start_index + chunks_added + j}" for j in range(len(batch))]

                # M√©tadonn√©es s√©curis√©es
                metadatas = []
                for j, chunk in enumerate(batch):
                    metadata = {
                        "source_file": source_info["filename"],
                        "author": source_info["config"]["author"],
                        "language": source_info["config"]["language"],
                        "chunk_index": start_index + chunks_added + j,
                        "bulletproof": True,
                        "text_preview": chunk[:100] + "..." if len(chunk) > 100 else chunk
                    }
                    metadatas.append(metadata)

                # Ajout s√©curis√©
                collection.add(
                    embeddings=embeddings,
                    documents=batch,
                    metadatas=metadatas,
                    ids=ids
                )

                chunks_added += len(batch)
                print(f"   üíæ {chunks_added}/{len(chunks)} chunks ajout√©s")

            return chunks_added

        except Exception as e:
            print(f"‚ùå Erreur ajout chunks: {e}")
            return 0

    def search_by_author(self, collection, author, query, n_results=3):
        """Recherche filtr√©e par auteur (√©vite les m√©langes)"""
        print(f"üîç Recherche '{query}' chez {author}")

        try:
            results = collection.query(
                query_texts=[query],
                n_results=n_results,
                where={"author": author},  # Filtre strict par auteur
                include=["documents", "metadatas", "distances"]
            )

            print(f"‚úÖ {len(results['documents'][0])} r√©sultats trouv√©s pour {author}")
            return results

        except Exception as e:
            print(f"‚ùå Erreur recherche: {e}")
            return None

    def ask_philosopher(self, collection, author, question, show_sources=True):
        """Ask a specific philosopher about a question"""
        if not self.anthropic_client:
            return {"error": "Anthropic client not initialized"}

        # Search for relevant content from the specific author
        search_results = self.search_by_author(collection, author, question, n_results=3)

        if not search_results or not search_results['documents'][0]:
            return {
                'answer': f"‚ùå Aucun contenu trouv√© pour {author}",
                'sources': [],
                'question': question,
                'author': author
            }

        relevant_passages = search_results['documents'][0]
        metadata_list = search_results['metadatas'][0]

        # Create context for Claude
        context = "\n\n".join([f"Passage {i+1}: {passage}" for i, passage in enumerate(relevant_passages)])

        # Create prompt adapted for specific philosopher
        prompt = f"""You are a philosophy expert helping someone understand {author}'s ethical thought.

Based on the following passages from {author}'s work, please answer the question about {author}'s philosophy.

RELEVANT PASSAGES FROM {author.upper()}:
{context}

QUESTION: {question}

Please provide a substantive response that accurately represents {author}'s philosophical position based on the provided passages. If the passages don't contain enough information to answer the question, please say so clearly.

TONE: Scholarly but accessible - maintain philosophical depth while being clear."""

        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=1000,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            answer = response.content[0].text

            result = {
                'answer': answer,
                'sources': [
                    {
                        'passage_number': i + 1,
                        'author': meta['author'],
                        'source_file': meta['source_file'],
                        'preview': meta['text_preview'],
                        'full_text': passage
                    }
                    for i, (passage, meta) in enumerate(zip(relevant_passages, metadata_list))
                ],
                'question': question,
                'author': author
            }

            return result

        except Exception as e:
            return {
                'answer': f"Error getting response: {str(e)}",
                'sources': [],
                'question': question,
                'author': author
            }
 ### cette partie a d√©j√† √©t√© test√©e et je pourrais sans doute l'enlever lorsque l'ensemble du programme aura ete test√© ###

    def verify_collection_integrity(self, collection):
        """V√©rifie l'int√©grit√© de la collection"""
        print("üîç V√âRIFICATION INT√âGRIT√â")
        print("=" * 40)

        sample = collection.get(limit=50, include=["metadatas", "documents"])

        authors_found = {}
        sources_found = {}
        bulletproof_count = 0

        for doc, meta in zip(sample["documents"], sample["metadatas"]):
            # Compter par auteur
            author = meta.get("author", "Unknown")
            authors_found[author] = authors_found.get(author, 0) + 1

            # Compter par source
            source = meta.get("source_file", "Unknown")
            sources_found[source] = sources_found.get(source, 0) + 1

            # V√©rifier bulletproof
            if meta.get("bulletproof"):
                bulletproof_count += 1

        print(f"üìä Auteurs trouv√©s: {authors_found}")
        print(f"üìÅ Sources trouv√©es: {sources_found}")
        print(f"üõ°Ô∏è  Chunks bulletproof: {bulletproof_count}/{len(sample['documents'])}")

        if len(authors_found) > 1:
            print("‚úÖ Collection multi-auteurs d√©tect√©e")
        else:
            print("‚ö†Ô∏è  Collection mono-auteur - v√©rifiez si normal")

        return {
            "authors": authors_found,
            "sources": sources_found,
            "bulletproof_ratio": bulletproof_count / len(sample["documents"])
        }

# =============================================================================
# INTERFACE SIMPLIFI√âE - √† terme les tests bullet proof peuvent sans doute √™tre enlev√©s
# =============================================================================

def bulletproof_setup(anthropic_key=None):
    """Setup rapide du syst√®me bulletproof"""
    print("üöÄ SETUP SYST√àME BULLETPROOF")
    print("=" * 50)

    # Initialiser le syst√®me
    system = BulletproofRAGSystem(anthropic_api_key=anthropic_key)

    # Ajouter toutes les sources disponibles
    collection = system.add_sources_incrementally()

    # V√©rifier l'int√©grit√©
    integrity = system.verify_collection_integrity(collection)

    print("\nüéâ SYST√àME PR√äT!")
    print(f"üìä Collection: {collection.count()} documents")
    print(f"üõ°Ô∏è  Int√©grit√©: {integrity['bulletproof_ratio']:.1%}")

    return system, collection

def test_bulletproof_search(system, collection):
    """Test des recherches s√©par√©es par auteur"""
    print("\nüß™ TEST RECHERCHES S√âPAR√âES")
    print("=" * 50)

    # Test Socrate
    print("\nüèõÔ∏è  RECHERCHE SOCRATE:")
    socrates_results = system.search_by_author(collection, "Platon", "What does Socrates say about death?")

    # Test Kant
    print("\nüß† RECHERCHE KANT:")
    kant_results = system.search_by_author(collection, "Kant", "synthetic a priori knowledge")

    return socrates_results, kant_results

# =============================================================================
# MAIN EXECUTION
# =============================================================================

if __name__ == "__main__":
    # Get API key from os
    
    
    import os
    from dotenv import load_dotenv
    load_dotenv()
    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')

    # Setup complet
    system, collection = bulletproof_setup(ANTHROPIC_API_KEY)

    # Tests
    test_bulletproof_search(system, collection)

# Western Ethics Bot - Complete User Interface
import time
from typing import Dict, List

# Improved Western Ethics Bot - Consistent Language + Off-topic Detection

import io
import sys
from contextlib import redirect_stdout, redirect_stderr

class SimpleTranslator:
    def __init__(self, anthropic_client):
        self.anthropic_client = anthropic_client
        self.cache = {}

    def translate_text(self, text: str, target_lang: str) -> str:
        # Code simple de traduction via Claude
        return text  # Pour l'instant, gardez simple

class SimpleLangDetector:
    def detect_language(self, text: str) -> str:
        # D√©tection simple
        if any(word in text.lower() for word in ['qu\'est-ce', 'comment', '√©thique']):
            return 'fran√ßais'
        elif any(word in text.lower() for word in ['what', 'how', 'ethics']):
            return 'english'
        return 'english'

# =============================================================================
# SYST√àME DE D√âTECTION √âTHIQUE INTELLIGENT
# =============================================================================

class EthicsDetector:
    """D√©tection intelligente des questions √©thiques avec LLM"""

    def __init__(self, anthropic_client):
        self.anthropic_client = anthropic_client
        self.cache = {}  # Cache pour √©viter les reclassifications

    def is_ethics_related(self, question: str) -> bool:
        """Classification LLM avec fallback intelligent"""

        # Cache simple
        question_hash = hash(question.lower().strip())
        if question_hash in self.cache:
            return self.cache[question_hash]

        try:
            # Classification par LLM
            classification_prompt = f"""Classify this question as ethics-related or not.

Question: "{question}"

Respond with only "YES" if about: ethics, morality, philosophy, justice, virtue, values, how to live, what is good/bad, rights, duties, fairness.

Respond with only "NO" if about: factual information, locations, objects, technology, science, weather, time, cooking, etc.

Answer:"""

            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=10,
                messages=[{"role": "user", "content": classification_prompt}]
            )

            result = response.content[0].text.strip().upper() == "YES"
            self.cache[question_hash] = result
            return result

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur classification LLM: {e}")
            # Fallback intelligent avec mots-cl√©s multilingues
            return self._fallback_classification(question)

    def _fallback_classification(self, question: str) -> bool:
        """Fallback avec mots-cl√©s √©tendus et multilingues"""
        ethics_keywords = {
            'fr': ['√©thique', 'moral', 'justice', 'vertu', 'bien', 'mal', 'devoir', 'vivre', 'juste'],
            'en': ['ethics', 'moral', 'justice', 'virtue', 'good', 'evil', 'duty', 'live', 'right', 'fair'],
            'es': ['√©tica', 'moral', 'justicia', 'virtud', 'bien', 'mal', 'deber', 'vivir', 'justo'],
            'de': ['ethik', 'moral', 'gerechtigkeit', 'tugend', 'gut', 'b√∂se', 'pflicht', 'leben', 'recht']
        }

        question_lower = question.lower()

        # Compter les matches dans toutes les langues
        total_matches = 0
        for lang_keywords in ethics_keywords.values():
            total_matches += sum(1 for word in lang_keywords if word in question_lower)

        return total_matches >= 1  # Seuil conservateur

# =============================================================================
# CORRECTIONS FINALES POUR LES PROBL√àMES IDENTIFI√âS
# =============================================================================


class ImprovedWesternEthicsBot:

    def __init__(self, rag_system, collection, anthropic_client):
        self.rag_system = rag_system
        self.collection = collection
        self.anthropic_client = anthropic_client
        self.bot_name = "Western_Ethics_Bot"
        self.current_language = None
        self.verbose_mode = False
        self.available_philosophers = self._detect_available_philosophers()
        self.ethics_detector = EthicsDetector(anthropic_client)

        # Simplified language system
        self.languages = {
            '1': 'fran√ßais', '2': 'english', '3': 'espa√±ol', '4': 'deutsch'
        }

        print("‚úÖ Bot final initialis√©!")

    def _get_system_prompt_for_language(self, author):
        language_prompts = {
        'fran√ßais': f"Vous √™tes {author}, un philosophe de r√©f√©rence. R√©pondez ENTI√àREMENT en fran√ßais dans un style professoral √©loquent mais accessible. Basez-vous uniquement sur les passages fournis dans le contexte.",

        'english': f"You are {author}, a great philosopher. Respond ENTIRELY in English in an eloquent but accessible professorial style. Base your response only on the passages provided in the context.",

        'espa√±ol': f"Usted es {author}, un gran fil√≥sofo. Responda COMPLETAMENTE en espa√±ol con un estilo profesoral elocuente pero accesible. Base su respuesta √∫nicamente en los pasajes proporcionados en el contexto.",

        'deutsch': f"Sie sind {author}, ein gro√üer Philosoph. Antworten Sie VOLLST√ÑNDIG auf Deutsch in einem eloquenten aber zug√§nglichen professoralen Stil. St√ºtzen Sie Ihre Antwort nur auf die im Kontext bereitgestellten Passagen."
    }
        return language_prompts.get(self.current_language, language_prompts['english'])

    def _get_text(self, key: str) -> str:
        """Textes complets dans toutes les langues"""
        texts = {
            'fran√ßais': {
                'welcome': "Bonjour! Je suis votre professeur de philosophie.",
                'menu_1': "R√©ponses individuelles de chaque philosophe",
                'menu_2': "Dialogue philosophique et synth√®se",
                'question_prompt': "Posez votre question philosophique",
                'question_input': "Votre question",
                'question_examples': ["‚Ä¢ Qu'est-ce que la justice?", "‚Ä¢ Comment devrions-nous vivre √©thiquement?"],
                'your_choice': "Votre choix",
                'off_topic': "Cette question ne porte pas sur l'√©thique. Je ne peux pas r√©pondre.",
                'error_question': "Veuillez entrer une question",
                'error_choice': "Choix invalide. Entrez 1, 2, 'exit', 'language', 'verbose' ou 'refresh'",
                'gathering': "Consultation des philosophes...",
                'complete': "Analyse termin√©e",
                'header_individual': "PERSPECTIVES PHILOSOPHIQUES INDIVIDUELLES",
                'header_synthesis': "DIALOGUE PHILOSOPHIQUE ET SYNTH√àSE",
                'synthesis_title': "SYNTH√àSE PHILOSOPHIQUE",
                'continue_prompt': "Voulez-vous poser une autre question? (o/n)",
                'continue_yes': ['o', 'oui'],
                'continue_all': ['o', 'oui', 'n', 'non'],
                'error_continue': "Veuillez entrer 'o' pour oui ou 'n' pour non",
                'goodbye_title': "AU REVOIR DE",
                'goodbye_msg': "Merci d'avoir explor√© l'√©thique occidentale avec moi!",
                'goodbye_quote': "Souvenez-vous: 'Une vie sans examen ne vaut pas la peine d'√™tre v√©cue' - Socrate",
                'citations': "Voulez-vous voir les sources et extraits utilis√©s? (o/n)",
                'overload_msg': "‚è≥ Les serveurs sont satur√©s. Veuillez r√©essayer dans une minute.",
                'flag': 'üá´üá∑',
                'name': 'Fran√ßais'
            },
            'english': {
                'welcome': "Hello! I'm your philosophy professor.",
                'menu_1': "Individual answers from each philosopher",
                'menu_2': "Philosophical dialogue and synthesis",
                'question_prompt': "Please ask your philosophical question",
                'question_input': "Your question",
                'question_examples': ["‚Ä¢ What is justice?", "‚Ä¢ How should we live ethically?"],
                'your_choice': "Your choice",
                'off_topic': "This question is not about ethics. I cannot answer it.",
                'error_question': "Please enter a question",
                'error_choice': "Invalid choice. Enter 1, 2, 'exit', 'language', 'verbose' or 'refresh'",
                'gathering': "Gathering perspectives from philosophers...",
                'complete': "Analysis complete",
                'header_individual': "INDIVIDUAL PHILOSOPHICAL PERSPECTIVES",
                'header_synthesis': "PHILOSOPHICAL DIALOGUE & SYNTHESIS",
                'synthesis_title': "PHILOSOPHICAL SYNTHESIS",
                'continue_prompt': "Would you like to ask another question? (y/n)",
                'continue_yes': ['y', 'yes'],
                'continue_all': ['y', 'yes', 'n', 'no'],
                'error_continue': "Please enter 'y' for yes or 'n' for no",
                'goodbye_title': "FAREWELL FROM",
                'goodbye_msg': "Thank you for exploring Western ethics with me!",
                'goodbye_quote': "Remember: 'The unexamined life is not worth living' - Socrates",
                'citations': "Would you like to see the sources and excerpts used? (y/n)",
                'overload_msg': "‚è≥ Servers are overloaded. Please try again in one minute.",
                'flag': 'üá∫üá∏',
                'name': 'English'
            },
            'espa√±ol': {
                'welcome': "¬°Hola! Soy su profesor de filosof√≠a.",
                'menu_1': "Respuestas individuales de cada fil√≥sofo",
                'menu_2': "Di√°logo filos√≥fico y s√≠ntesis",
                'question_prompt': "Haga su pregunta filos√≥fica",
                'question_input': "Su pregunta",
                'question_examples': ["‚Ä¢ ¬øQu√© es la justicia?", "‚Ä¢ ¬øC√≥mo deber√≠amos vivir √©ticamente?"],
                'your_choice': "Su elecci√≥n",
                'off_topic': "Esta pregunta no es sobre √©tica. No puedo responderla.",
                'error_question': "Por favor ingrese una pregunta",
                'error_choice': "Opci√≥n inv√°lida. Ingrese 1, 2, 'exit', 'language', 'verbose' o 'refresh'",
                'gathering': "Consultando fil√≥sofos...",
                'complete': "An√°lisis completo",
                'header_individual': "PERSPECTIVAS FILOS√ìFICAS INDIVIDUALES",
                'header_synthesis': "DI√ÅLOGO FILOS√ìFICO Y S√çNTESIS",
                'synthesis_title': "S√çNTESIS FILOS√ìFICA",
                'continue_prompt': "¬øLe gustar√≠a hacer otra pregunta? (s/n)",
                'continue_yes': ['s', 's√≠', 'si'],
                'continue_all': ['s', 's√≠', 'si', 'n', 'no'],
                'error_continue': "Por favor ingrese 's' para s√≠ o 'n' para no",
                'goodbye_title': "ADI√ìS DE",
                'goodbye_msg': "¬°Gracias por explorar la √©tica occidental conmigo!",
                'goodbye_quote': "Recuerda: 'Una vida sin examen no vale la pena vivirla' - S√≥crates",
                'citations': "¬øLe gustar√≠a ver las fuentes y extractos? (s/n)",
                'overload_msg': "‚è≥ Los servidores est√°n saturados. Por favor, int√©ntelo de nuevo en un minuto.",
                'flag': 'üá™üá∏',
                'name': 'Espa√±ol'
            },
            'deutsch': {
                'welcome': "Hallo! Ich bin Ihr Philosophieprofessor.",
                'menu_1': "Individuelle Antworten jedes Philosophen",
                'menu_2': "Philosophischer Dialog und Synthese",
                'question_prompt': "Stellen Sie Ihre philosophische Frage",
                'question_input': "Ihre Frage",
                'question_examples': ["‚Ä¢ Was ist Gerechtigkeit?", "‚Ä¢ Wie sollten wir ethisch leben?"],
                'your_choice': "Ihre Wahl",
                'off_topic': "Diese Frage handelt nicht von Ethik. Ich kann sie nicht beantworten.",
                'error_question': "Bitte geben Sie eine Frage ein",
                'error_choice': "Ung√ºltige Wahl. Geben Sie 1, 2, 'exit', 'language', 'verbose' oder 'refresh' ein",
                'gathering': "Philosophen werden konsultiert...",
                'complete': "Analyse abgeschlossen",
                'header_individual': "INDIVIDUELLE PHILOSOPHISCHE PERSPEKTIVEN",
                'header_synthesis': "PHILOSOPHISCHER DIALOG UND SYNTHESE",
                'synthesis_title': "PHILOSOPHISCHE SYNTHESE",
                'continue_prompt': "M√∂chten Sie eine weitere Frage stellen? (j/n)",
                'continue_yes': ['j', 'ja'],
                'continue_all': ['j', 'ja', 'n', 'nein'],
                'error_continue': "Bitte geben Sie 'j' f√ºr ja oder 'n' f√ºr nein ein",
                'goodbye_title': "AUF WIEDERSEHEN VON",
                'goodbye_msg': "Danke, dass Sie die westliche Ethik mit mir erkundet haben!",
                'goodbye_quote': "Denken Sie daran: 'Ein ungepr√ºftes Leben ist nicht lebenswert' - Sokrates",
                'citations': "M√∂chten Sie die verwendeten Quellen und Ausz√ºge? (j/n)",
                'overload_msg': "‚è≥ Die Server sind √ºberlastet. Bitte versuchen Sie es in einer Minute erneut.",
                'flag': 'üá©üá™',
                'name': 'Deutsch'
            }
        }

        current_texts = texts.get(self.current_language, texts['english'])
        return current_texts.get(key, key)

    def _detect_available_philosophers(self):
        """D√©tection des philosophes"""
        try:
            total_count = self.collection.count()
            sample_size = min(total_count, 8000)

            sample = self.collection.get(
                limit=sample_size,
                include=["metadatas"]
            )

            authors = set()
            for meta in sample["metadatas"]:
                author = meta.get("author", "Unknown")
                if author != "Unknown":
                    authors.add(author)

            authors_list = sorted(list(authors))
            return authors_list if authors_list else ["Platon", "Kant", "Rawls"]

        except Exception as e:
            if self.verbose_mode:
                print(f"‚ö†Ô∏è Error detecting philosophers: {e}")
            return ["Platon", "Kant", "Rawls"]

    def _ask_philosopher_strict(self, author, question):
        """VERSION STRICTE avec style professoral naturel"""

        if self.verbose_mode:
            print(f"üîç Recherche dans les sources de {author}...")

        # 1. Recherche dans les sources charg√©es
        search_results = self.rag_system.search_by_author(
            self.collection, author, question, n_results=5
        )

        if not search_results or not search_results['documents'][0]:
            if self.verbose_mode:
                print(f"‚ùå Aucune source trouv√©e pour {author}")

            no_source_msg = f"Les textes de {author} que j'ai √† disposition ne contiennent pas d'informations sur ce sujet."
            return {
                'answer': no_source_msg,
                'sources': [],
                'author': author,
                'has_sources': False
            }

        if self.verbose_mode:
            print(f"‚úÖ {len(search_results['documents'][0])} passages trouv√©s")
            sources = [meta.get('source_file', 'Unknown') for meta in search_results['metadatas'][0]]
            print(f"üìö Sources: {list(set(sources))}")

        # 2. Construire contexte strict
        relevant_passages = search_results['documents'][0]
        metadata_list = search_results['metadatas'][0]

        context = "\n\n".join([
            f"Passage {i+1}: {passage}"
            for i, passage in enumerate(relevant_passages)
        ])

        # 3. Prompt STRICT avec style professoral naturel
        strict_prompt = self._create_eloquent_prompt(author, question, context)

        if self.verbose_mode:
            print(f"ü§ñ G√©n√©ration de la r√©ponse par Claude...")

        try:

            system_prompt = self._get_system_prompt_for_language(author)
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                system=system_prompt,
                max_tokens=1000,  # Augment√© pour plus d'√©loquence
                messages=[{"role": "user", "content": strict_prompt}]
            )

            if self.verbose_mode:
                print(f"‚úÖ R√©ponse g√©n√©r√©e ({len(response.content[0].text)} caract√®res)")

            return {
                'answer': response.content[0].text,
                'sources': metadata_list,
                'author': author,
                'has_sources': True,
                'passages': relevant_passages
            }

        except Exception as e:
            error_str = str(e)

        # AJOUT: D√©tection overload pour sc√©nario 1 aussi
            if "529" in error_str or "overloaded" in error_str.lower():
              print(f"\n{self._get_text('overload_msg')}")
              return {
                'answer': "OVERLOAD_DETECTED",
                'sources': [],
                'author': author,
                'has_sources': False,
                'overload': True  # Flag sp√©cial
              }
            else:
                if self.verbose_mode:
                    print(f"‚ùå Erreur g√©n√©ration: {e}")
                return {
                    'answer': f"Erreur: {str(e)}",
                    'sources': [],
                    'author': author,
                    'has_sources': False
                }


## Essay√© de remanier le prompt, pour √©viter le style t√©l√©graphique √† tester ##

    def _create_eloquent_prompt(self, author, question, context):
        """CORRECTION: Prompt plus √©loquent, moins t√©l√©graphique"""

        if self.current_language == 'fran√ßais':
            return f"""En tant que {author},  vous allez r√©pondre √† cette question avec l'√©loquence et la profondeur qui vous caract√©risent.

TEXTES √Ä VOTRE DISPOSITION:
{context}

QUESTION: {question}

INSTRUCTIONS:
‚Ä¢ R√©pondez en fran√ßais dans le style d'un professeur de philosophie aimant partager
‚Ä¢ Basez-vous UNIQUEMENT sur les passages fournis ci-dessus
‚Ä¢ Si les passages ne suffisent pas, dites-le clairement mais avec finesse
‚Ä¢ D√©veloppez votre pens√©e avec des exemples et des nuances
‚Ä¢ Adoptez un ton acad√©mique mais accessible, ni t√©l√©graphique ni pompeux
‚Ä¢ Montrez la richesse de votre r√©flexion philosophique

Votre r√©ponse en tant que {author}:"""

        elif self.current_language == 'english':
            return f"""As {author},  you will answer this question with the eloquence and depth that characterizes your thought.

TEXTS AT YOUR DISPOSAL:
{context}

QUESTION: {question}

INSTRUCTIONS:
‚Ä¢ Answer in English in the style of a philosophy professor who loves to share
‚Ä¢ Base your response ONLY on the passages provided above
‚Ä¢ If the passages are insufficient, say so clearly but with finesse
‚Ä¢ Develop your thought with examples and nuances
‚Ä¢ Adopt a professorial but accessible tone, neither telegraphic nor pompous
‚Ä¢ Show the richness of your philosophical reflection

Your response as {author}:"""

        elif self.current_language == 'espa√±ol':
            return f"""Como {author}, responder√° a esta pregunta con la elocuencia y profundidad que caracteriza su pensamiento.

TEXTOS A SU DISPOSICI√ìN:
{context}

PREGUNTA: {question}

INSTRUCCIONES:
‚Ä¢ Responda en espa√±ol al estilo de un profesor de filosof√≠a que ama compartir
‚Ä¢ Base su respuesta √öNICAMENTE en los pasajes proporcionados anteriormente
‚Ä¢ Si los pasajes no son suficientes, d√≠galo claramente pero con delicadeza
‚Ä¢ Desarrolle su pensamiento con ejemplos y matices
‚Ä¢ Adopte un tono profesoral pero accesible, ni telegr√°fico ni pomposo
‚Ä¢ Muestre la riqueza de su reflexi√≥n filos√≥fica

Su respuesta como {author}:"""

        else:  # deutsch
            return f"""Als {author}, werden Sie diese Frage mit der Eloquenz und Tiefe beantworten, die Ihr Denken charakterisiert.

TEXTE ZU IHRER VERF√úGUNG:
{context}

FRAGE: {question}

ANWEISUNGEN:
‚Ä¢ Antworten Sie auf Deutsch im Stil eines Philosophieprofessors der gerne teilt
‚Ä¢ St√ºtzen Sie Ihre Antwort NUR auf die oben bereitgestellten Passagen
‚Ä¢ Wenn die Passagen nicht ausreichen, sagen Sie es klar aber mit Feingef√ºhl
‚Ä¢ Entwickeln Sie Ihren Gedanken mit Beispielen und Nuancen
‚Ä¢ Nehmen Sie einen professoralen aber zug√§nglichen Ton an, weder telegrafisch noch pomp√∂s
‚Ä¢ Zeigen Sie den Reichtum Ihrer philosophischen Reflexion

Ihre Antwort als {author}:"""

    #def _format_off_topic_message(self, width=60):
    #    """Formate le message off-topic"""
     #   import textwrap

     #   message = self._get_text('off_topic')
     #   wrapped = textwrap.fill(
      ##      message,
      #      width=width-4,
      #      break_long_words=False,
       #     break_on_hyphens=False
      #  )
      #  return f"‚ùå {wrapped}"

    def display_welcome(self, width=60):
        """√âcran de bienvenue"""
        print("=" * width)
        print(f"üèõÔ∏è  WELCOME TO {self.bot_name.upper()} üèõÔ∏è".center(width))
        print("=" * width)
        print(f"{self._get_text('welcome')}")
        print(f"")
        print(f"üìö Available philosophers ({len(self.available_philosophers)}):")
        for philosopher in self.available_philosophers:
            print(f"   üé≠ {philosopher}")
        print("=" * width)

    def select_language(self, width=60):
        """S√©lection de langue"""
        print(f"\nüåç LANGUAGE SELECTION")
        print("-" * width)
        print(f"Please choose your preferred language:")
        print(f"(All responses will be in this language)")
        print(f"")

        language_info = {
            '1': {'flag': 'üá´üá∑', 'name': 'Fran√ßais'},
            '2': {'flag': 'üá∫üá∏', 'name': 'English'},
            '3': {'flag': 'üá™üá∏', 'name': 'Espa√±ol'},
            '4': {'flag': 'üá©üá™', 'name': 'Deutsch'}
        }

        for key, info in language_info.items():
            print(f"   {key}Ô∏è‚É£  {info['flag']} {info['name']}")

        while True:
            choice = input(f"\nüó£Ô∏è Your choice (1-4): ").strip()

            if choice in self.languages:
                self.current_language = self.languages[choice]
                selected_info = language_info[choice]
                print(f"\n‚úÖ Language set to: {selected_info['flag']} {selected_info['name']}")
                return
            else:
                print(f"‚ùå Invalid choice. Please enter 1, 2, 3, or 4")

## dans le menu display seuls les choix de la question et du type de reponse 1 ou 2 sont dans la langue choisie; les menus fonctionnels sont toujours en anglais##
    def display_menu(self, width=60):
        """Menu dans la langue courante"""
        print(f"\nü§î {self._get_text('question_prompt')}?")
        print(f"   1Ô∏è‚É£  {self._get_text('menu_1')}")
        print(f"   2Ô∏è‚É£  {self._get_text('menu_2')}")
        print(f"   üîß Type 'verbose' for process details")
        print(f"   üîÑ Type 'refresh' to re-detect philosophers")
        print(f"   üåç Type 'language' to change language")
        print(f"   üö™ Type 'exit' to leave")

    def get_user_choice(self):
        """Choix utilisateur"""
        while True:
            choice = input(f"\nüìù {self._get_text('your_choice')}: ").strip().lower()

            if choice in ['1', '2', 'exit', 'language', 'verbose', 'refresh']:
                return choice
            else:
                print(f"‚ùå {self._get_text('error_choice')}")

    def get_user_question(self, width=60):
        """Obtention de question"""
        print(f"\nüí≠ {self._get_text('question_prompt')}:")
        print(f"   Examples:")

        examples = self._get_text('question_examples')
        for example in examples:
            print(f"   {example}")

        while True:
            question = input(f"\n‚ùì {self._get_text('question_input')}: ").strip()
            if question:
                if not self.ethics_detector.is_ethics_related(question):
                    print(f"\n{self._format_off_topic_message(width)}")
                    continue
                return question
            else:
                print(f"‚ùå {self._get_text('error_question')}")

### Dans scenario 1 voir si on ne peut pas simplifier le programme des r√©f√©rences. Il s'agit ##
###d'avoir une option CITATIONS qui est activ√©e en fin de programme et si d√©sir√© fournit ##
###des citations utilis√©es dans la reponse pour tous les auteurs###

    def scenario_1_individual_answers(self, question, width=60):
        """AM√âLIORATION: Citations globales au lieu d'individuelles"""
        print(f"\n" + "=" * width)
        print(self._get_text('header_individual').center(width))
        print("=" * width)
        print(f"‚ùì Question: {question}")
        print()

        all_responses = {}
        overload_detected = False

        # Collecter toutes les r√©ponses
        for i, philosopher in enumerate(self.available_philosophers):
            print(f"\nüéØ PERSPECTIVE DE {philosopher.upper()}:")
            print("-" * width)

            response_data = self._ask_philosopher_strict(philosopher, question)
            if response_data.get('overload', False):
              overload_detected = True
              break  # Arr√™ter imm√©diatement si overload
            formatted_answer = self.format_philosopher_response(response_data['answer'], width)
            print(formatted_answer)

            # Stocker pour citations globales
            if response_data.get('has_sources', False):
                all_responses[philosopher] = response_data

            if i < len(self.available_philosophers) - 1:
                print(f"\n" + "-" * width)
        if overload_detected:
            return "OVERLOAD_DETECTED"
        # IMPROVED: Single citation question for all philosophers
        if all_responses:
          print(f"\nüí° {self._get_text('citations')}", end=" ")
          choice = input().strip().lower()

          # Multi-language yes detection
          yes_variants = self._get_text('continue_yes') + ['y', 'yes', 's', 's√≠', 'si', 'j', 'ja']

          if choice in yes_variants:
              print(f"\nüìö SOURCES UTILIS√âES PAR AUTEUR:")
              print("=" * width)

              for philosopher, response_data in all_responses.items():
                print(f"\nüé≠ {philosopher.upper()}:")
                print("-" * (width//2))

                passages = response_data.get('passages', [])
                sources = response_data.get('sources', [])

                if not passages or not sources:
                    print(f"   ‚ö†Ô∏è Aucune source sp√©cifique trouv√©e")
                    continue

                # Afficher 2-3 extraits pertinents
                for i, (passage, source) in enumerate(zip(passages[:3], sources[:3])):
                    source_file = source.get('source_file', 'Source inconnue')
                    excerpt = self._extract_relevant_excerpt(passage, 180)

                    print(f"\n   üìñ {source_file}:")
                    print(f"   üí¨ \"{excerpt}\"")

                    if i < min(len(passages), len(sources)) - 1 and i < 2:
                        print()

        return all_responses

    def _extract_relevant_excerpt(self, passage, max_length=180):
      """Extrait un passage pertinent du chunk"""
      import re

      # Nettoyer le passage
      cleaned_passage = passage

      # Supprimer les m√©tadonn√©es bulletproof si pr√©sentes
      if "[BULLETPROOF_METADATA]" in cleaned_passage:
          parts = cleaned_passage.split("[/BULLETPROOF_METADATA]")
          if len(parts) > 1:
              cleaned_passage = parts[1].strip()

      # Supprimer les num√©ros de passage ("Passage 1:", etc.)
      cleaned_passage = re.sub(r'^Passage \d+:\s*', '', cleaned_passage)

      # Si le passage est court, le retourner enti√®rement
      if len(cleaned_passage) <= max_length:
          return cleaned_passage.strip()

      # Sinon, prendre les premi√®res phrases compl√®tes
      sentences = re.split(r'[.!?]+', cleaned_passage)
      excerpt = ""

      for sentence in sentences:
          sentence = sentence.strip()
          if not sentence:
              continue

          # V√©rifier si on peut ajouter cette phrase
          test_excerpt = excerpt + sentence + "."
          if len(test_excerpt) <= max_length:
              excerpt = test_excerpt
          else:
              break

      # Si pas d'excerpt valide, prendre les premiers mots
      if not excerpt.strip():
          words = cleaned_passage.split()
          excerpt = " ".join(words[:25]) + "..."

      return excerpt.strip()

    def scenario_2_philosophical_dialogue(self, question, width=60):
        """Mode synth√®se avec am√©lioration anti-banalit√© et overload"""
        print(f"\n" + "=" * width)
        print(self._get_text('header_synthesis').center(width))
        print("=" * width)
        print(f"‚ùì Question: {question}")
        print()

        print(self._get_text('gathering'))

        individual_responses = {}
        for philosopher in self.available_philosophers:
            response = self._ask_philosopher_strict(philosopher, question)
            if response and response.get('has_sources', False):
                individual_responses[philosopher] = response

        if not individual_responses:
            print("‚ùå Unable to gather philosophical perspectives")
            return None

        print(f"{self._get_text('complete')}\n")

        synthesis = self._create_anti_banal_synthesis(question, individual_responses)
        if synthesis == "OVERLOAD_DETECTED":
            return "OVERLOAD_DETECTED"  # Signal pour la boucle principale
        print(f"{self._get_text('synthesis_title')}:")
        print("-" * width)
        formatted_synthesis = self.format_philosopher_response(synthesis, width)
        print(formatted_synthesis)

        return synthesis
##==================CORRECTION MULTI LINGUE====================

    def _create_anti_banal_synthesis(self, question, responses):
        """FIXED: Complete synthesis prompts for all languages"""
        dialogue_context = f"Question: {question}\n\n"
        for philosopher, response in responses.items():
            dialogue_context += f"{philosopher}: {response['answer']}\n\n"

        # FIXED: Complete prompts for espa√±ol and deutsch
        if self.current_language == 'fran√ßais':
            prompt = f"""Vous √™tes un professeur de philosophie de haut niveau. Analysez ces perspectives avec une rigueur acad√©mique exceptionnelle.

    {dialogue_context}

    Cr√©ez une synth√®se structur√©e en 3 sections pr√©cises:

    **CONVERGENCES PHILOSOPHIQUES:**
    [Identifiez les points d'accord conceptuels pr√©cis, avec arguments]

    **DIVERGENCES TH√âORIQUES:**
    [Analysez les oppositions fondamentales, expliquez pourquoi elles existent]

    **APPORT CRITIQUE:**
    [√âvaluez quelle approche est la plus convaincante et pourquoi]

    INSTRUCTIONS STRICTES:
    ‚Ä¢ INTERDICTION absolue de phrases banales comme "cette analyse sugg√®re que...", "une compr√©hension compl√®te n√©cessite...", "cette r√©flexion montre que..."
    ‚Ä¢ √âvitez toute conclusion g√©n√©rique ou passe-partout
    ‚Ä¢ Terminez par un jugement philosophique substantiel et pr√©cis, mais s'il n'y a rien √† rajouter d'utile, n'ajoutez rien
    ‚Ä¢ Style acad√©mique mais incisif, pas de langue de bois
    ‚Ä¢ Concentrez-vous sur les enjeux philosophiques r√©els, pas sur des platitudes

    Synth√®se philosophique rigoureuse:"""

        elif self.current_language == 'english':
            prompt = f"""You are a high-level philosophy professor. Analyze these perspectives with exceptional academic rigor.

    {dialogue_context}

    Create a structured synthesis in 3 precise sections:

    **PHILOSOPHICAL CONVERGENCES:**
    [Identify precise conceptual agreements, with arguments]

    **THEORETICAL DIVERGENCES:**
    [Analyze fundamental oppositions, explain why they exist]

    **CRITICAL CONTRIBUTION:**
    [Evaluate which approach is most convincing and why]

    STRICT INSTRUCTIONS:
    ‚Ä¢ ABSOLUTE PROHIBITION of banal phrases like "this analysis suggests that...", "a comprehensive understanding requires...", "this reflection shows that..."
    ‚Ä¢ Avoid any generic or catch-all conclusions
    ‚Ä¢ End with a substantial and precise philosophical judgment, but if there is nothing useful to add, do not add anything
    ‚Ä¢ Academic but incisive style, no empty rhetoric
    ‚Ä¢ Focus on real philosophical issues, not platitudes

    Rigorous philosophical synthesis:"""

        elif self.current_language == 'espa√±ol':
            prompt = f"""Usted es un profesor de filosof√≠a de alto nivel. Analice estas perspectivas con rigor acad√©mico excepcional.

    {dialogue_context}

    Cree una s√≠ntesis estructurada en 3 secciones precisas:

    **CONVERGENCIAS FILOS√ìFICAS:**
    [Identifique acuerdos conceptuales precisos, con argumentos]

    **DIVERGENCIAS TE√ìRICAS:**
    [Analice las oposiciones fundamentales, explique por qu√© existen]

    **CONTRIBUCI√ìN CR√çTICA:**
    [Eval√∫e qu√© enfoque es m√°s convincente y por qu√©]

    INSTRUCCIONES ESTRICTAS:
    ‚Ä¢ PROHIBICI√ìN absoluta de frases banales como "este an√°lisis sugiere que...", "una comprensi√≥n completa requiere...", "esta reflexi√≥n muestra que..."
    ‚Ä¢ Evite cualquier conclusi√≥n gen√©rica o comod√≠n
    ‚Ä¢ Termine con un juicio filos√≥fico sustancial y preciso, pero si no hay nada √∫til que agregar, no agregue nada
    ‚Ä¢ Estilo acad√©mico pero incisivo, no ret√≥rica vac√≠a
    ‚Ä¢ Conc√©ntrese en cuestiones filos√≥ficas reales, no en t√≥picos

    S√≠ntesis filos√≥fica rigurosa:"""

        else:  # deutsch
            prompt = f"""Sie sind ein hochrangiger Philosophieprofessor. Analysieren Sie diese Perspektiven mit au√üergew√∂hnlicher akademischer Strenge.

    {dialogue_context}

    Erstellen Sie eine strukturierte Synthese in 3 pr√§zisen Abschnitten:

    **PHILOSOPHISCHE KONVERGENZEN:**
    [Identifizieren Sie pr√§zise konzeptionelle √úbereinstimmungen, mit Argumenten]

    **THEORETISCHE DIVERGENZEN:**
    [Analysieren Sie fundamentale Gegens√§tze, erkl√§ren Sie warum sie existieren]

    **KRITISCHER BEITRAG:**
    [Bewerten Sie welcher Ansatz √ºberzeugender ist und warum]

    STRENGE ANWEISUNGEN:
    ‚Ä¢ ABSOLUTES VERBOT banaler Phrasen wie "diese Analyse deutet darauf hin, dass...", "ein umfassendes Verst√§ndnis erfordert...", "diese Reflexion zeigt, dass..."
    ‚Ä¢ Vermeiden Sie jede generische oder Allzweck-Schlussfolgerung
    ‚Ä¢ Beenden Sie mit einem substantiellen und pr√§zisen philosophischen Urteil, aber wenn nichts N√ºtzliches hinzuzuf√ºgen ist, f√ºgen Sie nichts hinzu
    ‚Ä¢ Akademischer aber scharfsinniger Stil, keine leere Rhetorik
    ‚Ä¢ Konzentrieren Sie sich auf echte philosophische Fragen, nicht auf Gemeinpl√§tze

    Rigorose philosophische Synthese:"""

        # FIXED: Language-specific system prompts
        system_prompts = {
            'fran√ßais': "Vous √™tes un professeur de philosophie distingu√©. Fournissez une analyse acad√©mique incisive. √âvitez absolument les conclusions g√©n√©riques et les clich√©s philosophiques. R√©pondez enti√®rement en fran√ßais.",
            'english': "You are a distinguished philosophy professor. Provide incisive academic analysis. Absolutely avoid generic conclusions and philosophical clich√©s. Respond entirely in English.",
            'espa√±ol': "Usted es un distinguido profesor de filosof√≠a. Proporcione un an√°lisis acad√©mico incisivo. Evite absolutamente las conclusiones gen√©ricas y los clich√©s filos√≥ficos. Responda completamente en espa√±ol.",
            'deutsch': "Sie sind ein angesehener Philosophieprofessor. Liefern Sie eine scharfsinnige akademische Analyse. Vermeiden Sie unbedingt generische Schlussfolgerungen und philosophische Klischees. Antworten Sie vollst√§ndig auf Deutsch."
        }


        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                system=system_prompts.get(self.current_language, system_prompts['english']),
                max_tokens=1200,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        except Exception as e:
            error_str = str(e)

            # AJOUT: D√©tection sp√©cifique de l'overload
            if "529" in error_str or "overloaded" in error_str.lower():
                print(f"\n{self._get_text('overload_msg')}")
                return "OVERLOAD_DETECTED"  # Signal sp√©cial
            else:
                return f"‚ùå Error creating synthesis: {e}"



    #def format_philosopher_response(self, text, width=60):
       # """Format texte avec retour √† la ligne"""
       # import textwrap
       # if not text:
      #      return text

     #   paragraphs = text.split('\n\n')
     #   wrapped_paragraphs = []

     #   for paragraph in paragraphs:
      #      if paragraph.strip():
      #          wrapped = textwrap.fill(
      #              paragraph.strip(),
      #              width=width,
       #             break_long_words=False,
       #             break_on_hyphens=False
       #         )
        #        wrapped_paragraphs.append(wrapped)
        #    else:
        #        wrapped_paragraphs.append("")

       # return '\n\n'.join(wrapped_paragraphs)

    def continue_session(self):
        """Demande de continuation"""
        while True:
            continue_choice = input(f"\nüîÑ {self._get_text('continue_prompt')}: ").strip().lower()
            if continue_choice in self._get_text('continue_all'):
                return continue_choice in self._get_text('continue_yes')
            else:
                print(f"‚ùå {self._get_text('error_continue')}")

    def display_goodbye(self, width=60):
        """Au revoir"""
        print(f"\n" + "=" * width)
        print(f"üëã {self._get_text('goodbye_title')} {self.bot_name}".center(width))
        print("=" * width)
        print(self._get_text('goodbye_msg'))
        print(self._get_text('goodbye_quote'))
        print("=" * width)

    def run(self, width=60):
        """Boucle principale avec gestion overload"""
        self.display_welcome(width)
        self.select_language(width)

        while True:
            self.display_menu(width)
            choice = self.get_user_choice()

            if choice == 'exit':
                self.display_goodbye(width)
                break
            elif choice == 'language':
                self.select_language(width)
                continue
            elif choice == 'verbose':
                self.verbose_mode = not self.verbose_mode
                status = "ON" if self.verbose_mode else "OFF"
                print(f"üîß Verbose mode: {status}")
                if self.verbose_mode:
                    print("   üîç Le mode verbose affiche les d√©tails du processus RAG:")
                    print("   ‚Ä¢ Recherche dans les sources")
                    print("   ‚Ä¢ Sources trouv√©es")
                    print("   ‚Ä¢ G√©n√©ration des r√©ponses")
                continue
            elif choice == 'refresh':
                old_count = len(self.available_philosophers)
                self.available_philosophers = self._detect_available_philosophers()
                new_count = len(self.available_philosophers)
                print(f"üîÑ Philosophers re-detected: {old_count} ‚Üí {new_count}")
                for philosopher in self.available_philosophers:
                    print(f"   üé≠ {philosopher}")
                continue

            question = self.get_user_question(width)

            if choice == '1':
                result = self.scenario_1_individual_answers(question, width)
                if result == "OVERLOAD_DETECTED":
                    continue  # Retour direct au menu sans demander de continuer
            elif choice == '2':
                result = self.scenario_2_philosophical_dialogue(question, width)
            # AJOUT: Si overload d√©tect√©, ne pas demander de continuer, juste reboucler
                if result == "OVERLOAD_DETECTED":
                    continue  # Retour direct au menu sans demander de continuer

            if not self.continue_session():
                self.display_goodbye(width)
                break

def start_improved_western_ethics_bot(system, collection, width=60):
    """Start the improved bot"""
    if not system.anthropic_client:
        print("‚ùå Anthropic client not initialized.")
        return

    bot = ImprovedWesternEthicsBot(system, collection, system.anthropic_client)
    bot.run(width)

print("‚úÖ Improved Western Ethics Bot ready!")
print("üîß Improvements:")
print("   üåç Consistent language in all modes")
print("   üö´ Off-topic question detection")
print("   üìù Simplified multilingual code")
print("   üéØ Better user experience")
print("üí° To start: start_improved_western_ethics_bot(system, collection)")

# Initialize the bot with your existing system
if __name__ == "__main__":
    print("üéØ Pour d√©marrer le bot :")
    print("   1. Initialisez d'abord : system, collection = bulletproof_setup(ANTHROPIC_API_KEY)")
    print("   2. Puis lancez : start_improved_western_ethics_bot(system, collection)")
